{
  "cells": [
    {
      "metadata": {
        "collapsed": true,
        "id": "initial_id"
      },
      "cell_type": "code",
      "outputs": [],
      "execution_count": null,
      "source": [
        "from typing import Tuple, Dict, List, Any\n",
        "import whisper\n",
        "from whisper.model import Whisper\n",
        "from pyannote.audio import Pipeline as DiarizationPipeline\n",
        "import torch\n",
        "import logging\n",
        "from pathlib import Path\n",
        "import json\n",
        "import ast\n",
        "from time import time\n",
        "from pydantic import BaseModel, Field\n",
        "\n",
        "def load_models(diarization_model_auth_token: str) -> Tuple[Whisper, DiarizationPipeline]:\n",
        "    \"\"\"\n",
        "    Load and return the transcription and diarization models.\n",
        "\n",
        "    Args:\n",
        "        diarization_model_auth_token (str): HuggingFace auth token for diarization model.\n",
        "\n",
        "    Returns:\n",
        "        Tuple[Whisper, DiarizationPipelineType]: (transcription_model, diarization_model)\n",
        "    \"\"\"\n",
        "    transcription_model = whisper.load_model(\"base\")\n",
        "    diarization_model = DiarizationPipeline.from_pretrained(\n",
        "        \"pyannote/speaker-diarization-3.1\",\n",
        "        use_auth_token=diarization_model_auth_token\n",
        "    ).to(torch.device(\"mps\") if torch.backends.mps.is_available() else torch.device(\"cpu\"))\n",
        "    return transcription_model, diarization_model"
      ],
      "id": "initial_id"
    },
    {
      "metadata": {
        "id": "c724d5a4916ba45a"
      },
      "cell_type": "code",
      "outputs": [],
      "execution_count": null,
      "source": [
        "# Transcription with timestamps\n",
        "def transcribe(\n",
        "    audio_path: Path,\n",
        "    transcription_model: whisper.model,\n",
        "    logging: = logging.Logger,\n",
        "    word_timestamps: bool = False,\n",
        ") -> Dict[str, str | List[Dict[str, object]] | None]:\n",
        "    try:\n",
        "        # Transcribe (get timestamps)\n",
        "        if not audio_path.exists():\n",
        "            raise FileNotFoundError(f\"Audio file not found: {audio_path}\")\n",
        "        result = transcription_model.transcribe(\n",
        "            str(audio_path), word_timestamps=word_timestamps\n",
        "        )\n",
        "        return result\n",
        "    except Exception as e:\n",
        "        logging.error(f\"Error during transcription: {e}\")\n",
        "        return {}"
      ],
      "id": "c724d5a4916ba45a"
    },
    {
      "metadata": {
        "id": "8a08a8515edab93d"
      },
      "cell_type": "code",
      "outputs": [],
      "execution_count": null,
      "source": [
        "# Speaker diarization\n",
        "def diarize_audio(\n",
        "    audio_path: Path, diarization_model: DiarizationPipeline, logging: logging.Logger\n",
        ") -> list[tuple[float, float, str]]:\n",
        "    # devide into speakers\n",
        "    try:\n",
        "        if not audio_path.exists():\n",
        "            raise FileNotFoundError(f\"Audio file not found: {audio_path}\")\n",
        "        diarization = diarization_model(audio_path)\n",
        "        return [\n",
        "            (segment.start, segment.end, label)\n",
        "            for segment, _, label in diarization.itertracks(yield_label=True)\n",
        "        ]\n",
        "    except Exception as e:\n",
        "        logging.error(f\"Error during diarization: {e}\")\n",
        "        return []"
      ],
      "id": "8a08a8515edab93d"
    },
    {
      "metadata": {
        "id": "7e3aa1c9da8370f3"
      },
      "cell_type": "code",
      "outputs": [],
      "execution_count": null,
      "source": [
        "def integrate_diarization_and_transcription(\n",
        "    diarization: List[tuple[float, float, str]],\n",
        "    transcription_chunks: List[Dict[str, object]] | None,\n",
        ") -> list[dict[str, object]]:\n",
        "    result = []\n",
        "\n",
        "    for chunk in transcription_chunks:\n",
        "        chunk_start = chunk[\"start\"]\n",
        "        chunk_end = chunk[\"end\"]\n",
        "        text = chunk[\"text\"]\n",
        "        chunk_text = text.strip()\n",
        "        if not chunk_text:\n",
        "            continue\n",
        "        best_match = None\n",
        "        max_overlap = 0\n",
        "\n",
        "        for turn_start, turn_end, speaker in diarization:\n",
        "            # Calculate overlap\n",
        "            overlap_start = max(chunk_start, turn_start)\n",
        "            overlap_end = min(chunk_end, turn_end)\n",
        "            overlap_duration = max(0.0, overlap_end - overlap_start)\n",
        "\n",
        "            if overlap_duration > max_overlap:\n",
        "                max_overlap = overlap_duration\n",
        "                best_match = (turn_start, turn_end, speaker)\n",
        "\n",
        "        if best_match and max_overlap > 0:\n",
        "            result.append(\n",
        "                {\n",
        "                    \"start\": chunk_start,\n",
        "                    \"end\": chunk_end,\n",
        "                    \"speaker\": best_match[2],\n",
        "                    \"content\": chunk_text,\n",
        "                }\n",
        "            )\n",
        "\n",
        "    # Sort results by transcription start time\n",
        "    result.sort(key=lambda x: x[\"start\"])\n",
        "    return result\n",
        "\n",
        "def merge_consecutive_speaker_segments(\n",
        "    segments: List[Dict[str, object]]\n",
        ") -> str:\n",
        "    \"\"\"\n",
        "    Merge consecutive speech segments by the same speaker into a single segment.\n",
        "\n",
        "    Args:\n",
        "        segments (List[Dict[str, object]]): A list of segments, each containing:\n",
        "            - \"start\" (float): start time of the segment\n",
        "            - \"end\" (float): end time of the segment\n",
        "            - \"speaker\" (str): speaker label (e.g., \"SPEAKER_00\")\n",
        "            - \"content\" (str): transcribed text of the segment\n",
        "\n",
        "    Returns:\n",
        "        List[Dict[str, object]]: A list of merged segments, where consecutive segments\n",
        "        from the same speaker are combined. Each merged segment includes:\n",
        "            - \"start\" (float): start time of the first segment in the group\n",
        "            - \"end\" (float): end time of the last segment in the group\n",
        "            - \"speaker\" (str): speaker label\n",
        "            - \"content\" (str): concatenated content\n",
        "    \"\"\"\n",
        "    if not segments:\n",
        "        return []\n",
        "\n",
        "    merged_segments: List[Dict[str, object]] = []\n",
        "    current = {\n",
        "        \"speaker\": segments[0][\"speaker\"],\n",
        "        \"start\": segments[0][\"start\"],\n",
        "        \"end\": segments[0][\"end\"],\n",
        "        \"content\": segments[0][\"content\"],\n",
        "    }\n",
        "\n",
        "    for seg in segments[1:]:\n",
        "        if seg[\"speaker\"] == current[\"speaker\"]:\n",
        "            current[\"end\"] = seg[\"end\"]\n",
        "            current[\"content\"] += \" \" + seg[\"content\"]\n",
        "        else:\n",
        "            merged_segments.append(current)\n",
        "            current = {\n",
        "                \"speaker\": seg[\"speaker\"],\n",
        "                \"start\": seg[\"start\"],\n",
        "                \"end\": seg[\"end\"],\n",
        "                \"content\": seg[\"content\"],\n",
        "            }\n",
        "\n",
        "    merged_segments.append(current)\n",
        "    merged_segments_json = json.dumps(merged_segments, indent=4)\n",
        "    return merged_segments_json\n"
      ],
      "id": "7e3aa1c9da8370f3"
    },
    {
      "metadata": {
        "id": "cce2746bf8ba6164"
      },
      "cell_type": "code",
      "outputs": [],
      "execution_count": null,
      "source": [
        "from anthropic import AnthropicBedrock\n",
        "\n",
        "def add_speakers_roles(transcription: str)-> str:\n",
        "    transcription = ast.literal_eval(transcription)\n",
        "    speakers_roles = {}\n",
        "    for speaker in set([speaker[\"speaker\"] for speaker in transcription]):\n",
        "        speakers_roles[speaker] = get_speaker_role(speaker, transcription)\n",
        "    for speaker in transcription:\n",
        "        speaker[\"speaker_role\"] = speakers_roles[speaker[\"speaker\"]]\n",
        "    transcription_with_speakers_roles = json.dumps(transcription, indent=4)\n",
        "    return transcription_with_speakers_roles\n",
        "\n",
        "def get_speaker_role(speaker: str, transcription: json) -> str:\n",
        "    prompt = f\"\"\"\n",
        "    You are given a JSON transcription of a conversation between multiple speakers, each labeled with a speaker name and their spoken content.\n",
        "\n",
        "    Task: Based on the speaker's name and the context of the conversation, determine the speaker's role (e.g., Doctor, Patient, Nurse, etc.).\n",
        "    If the role is unclear or cannot be inferred confidently, return \"Unknown\".\n",
        "\n",
        "    The speaker's role should:\n",
        "    - Be consistent throughout the conversation.\n",
        "    - Be inferred from both the speaker's name and the conversational context.\n",
        "    - Be returned **as a single string only**, with no explanations.\n",
        "\n",
        "    The speaker name is: {speaker}\n",
        "    The transcription is:\n",
        "    {json.dumps(transcription)}\n",
        "    \"\"\"\n",
        "    claude_client = AnthropicBedrock(aws_region=\"us-east-1\")\n",
        "    response = claude_client.messages.create(\n",
        "        model=\"us.anthropic.claude-3-7-sonnet-20250219-v1:0\",\n",
        "        max_tokens=8192,\n",
        "        system=\"\",\n",
        "        messages=[{\"role\": \"user\", \"content\": prompt}],\n",
        "        temperature=0.0,\n",
        "    )\n",
        "    return response.content[0].text\n"
      ],
      "id": "cce2746bf8ba6164"
    },
    {
      "metadata": {
        "id": "b46c94515e80d9de"
      },
      "cell_type": "code",
      "outputs": [],
      "execution_count": null,
      "source": [
        "async def diarize_and_integrate(\n",
        "    audio_path: Path,\n",
        "    transcription_results: Dict[str, str | List[Dict[str, object]] | None],\n",
        "    diarization_model: DiarizationPipeline,\n",
        "    logging: logging.Logger,\n",
        ") -> str:\n",
        "    diarization_results = diarize_audio(audio_path, diarization_model, logging)\n",
        "    integrated_data = integrate_diarization_and_transcription(\n",
        "        diarization_results, transcription_results[\"segments\"]\n",
        "    )\n",
        "    meeting_minutes = merge_consecutive_speaker_segments(integrated_data)\n",
        "    meeting_minutes = add_speakers_roles(meeting_minutes)\n",
        "    return meeting_minutes\n",
        "\n",
        "async def transcription_and_diarization_main(audio_file_path: Path, diarization_model_auth_token: str) -> str:\n",
        "    # Initialize models\n",
        "    device = torch.device(\"mps\") if torch.backends.mps.is_available() else torch.device(\"cpu\")\n",
        "\n",
        "    transcription_model = whisper.load_model(\"base\")\n",
        "\n",
        "    auth_token = diarization_model_auth_token\n",
        "    diarization_model = DiarizationPipeline.from_pretrained(\n",
        "        \"pyannote/speaker-diarization-3.1\", use_auth_token=auth_token\n",
        "    )\n",
        "    diarization_model.to(device)\n",
        "    # Step 1: Transcribe audio\n",
        "    logging.info(\"Starting transcription...\")\n",
        "    start_time = time()\n",
        "    transcription_results = transcribe(\n",
        "        audio_file_path,\n",
        "        transcription_model,\n",
        "        logging.getLogger(),\n",
        "        word_timestamps=True,\n",
        "    )\n",
        "    print(f\"Transcription time: {time() - start_time:.2f} seconds\")\n",
        "    logging.info(\"Transcription completed.\")\n",
        "\n",
        "    # Step 2: Diarize and integrate\n",
        "    logging.info(\"Starting diarization and integration...\")\n",
        "    start_time = time()\n",
        "    integrated_results = await diarize_and_integrate(\n",
        "        audio_file_path,\n",
        "        transcription_results,\n",
        "        diarization_model,\n",
        "        logging.getLogger(),\n",
        "    )\n",
        "    print(f\"Diarization and integration time: {time() - start_time:.2f} seconds\")\n",
        "    logging.info(\"Diarization and integration completed.\")\n",
        "\n",
        "    return integrated_results"
      ],
      "id": "b46c94515e80d9de"
    },
    {
      "metadata": {
        "id": "11c6f34dce29316f"
      },
      "cell_type": "code",
      "outputs": [],
      "execution_count": null,
      "source": [
        "# Medical Report Extraction and Analysis from Conversation\n",
        "\n",
        "class ICD10Code(BaseModel):\n",
        "    \"\"\"\n",
        "    Represents a single ICD-10 code and its description.\n",
        "    \"\"\"\n",
        "    code: str = Field(..., description=\"The ICD-10 code\")\n",
        "    description: str = Field(..., description=\"The description of the ICD-10 code\")\n",
        "\n",
        "\n",
        "class ICD10Codes(BaseModel):\n",
        "    \"\"\"\n",
        "    Represents a list of ICD-10 codes.\n",
        "    \"\"\"\n",
        "    codes: List[ICD10Code] = Field(..., description=\"The ICD-10 codes\")\n",
        "\n",
        "\n",
        "class CPTCode(BaseModel):\n",
        "    \"\"\"\n",
        "    Represents a single CPT code and its description.\n",
        "    \"\"\"\n",
        "    code: str = Field(..., description=\"The CPT code\")\n",
        "    description: str = Field(..., description=\"The description of the CPT code\")\n",
        "\n",
        "\n",
        "class CPTCodes(BaseModel):\n",
        "    \"\"\"\n",
        "    Represents a list of CPT codes.\n",
        "    \"\"\"\n",
        "    codes: List[CPTCode] = Field(..., description=\"The CPT codes\")\n",
        "\n",
        "\n",
        "class ConversationReportAnalysis(BaseModel):\n",
        "    \"\"\"\n",
        "    Represents the full analysis of a conversation report, including all relevant medical fields and codes.\n",
        "    \"\"\"\n",
        "    chief_complaint: str = Field(..., description=\"The chief complaint of the patient\")\n",
        "    history_of_present_illness: str = Field(..., description=\"The history of present illness of the patient\")\n",
        "    past_medical_history: str = Field(..., description=\"The past medical history of the patient\")\n",
        "    past_surgical_history: str = Field(..., description=\"The past surgical history of the patient\")\n",
        "    medications: str = Field(..., description=\"The medications the patient is taking\")\n",
        "    allergies: str = Field(..., description=\"The allergies the patient has\")\n",
        "    family_history: str = Field(..., description=\"The family history of the patient\")\n",
        "    social_history: str = Field(..., description=\"The social history of the patient\")\n",
        "    review_of_systems: str = Field(..., description=\"The review of systems of the patient\")\n",
        "    neurological: str = Field(..., description=\"The neurological findings of the patient\")\n",
        "    psychiatric: str = Field(..., description=\"The psychiatric findings of the patient\")\n",
        "    endocrine: str = Field(..., description=\"The endocrine findings of the patient\")\n",
        "    hematologic_lymphatic: str = Field(..., description=\"The hematologic/lymphatic findings of the patient\")\n",
        "    allergic_immunologic: str = Field(..., description=\"The allergic/immunologic findings of the patient\")\n",
        "    physical_exam: str = Field(..., description=\"The physical exam of the patient\")\n",
        "    labs: str = Field(..., description=\"The labs of the patient\")\n",
        "    imaging: str = Field(..., description=\"The imaging of the patient\")\n",
        "    assessment_and_plan: str = Field(..., description=\"The assessment and plan of the patient\")\n",
        "    icd10_codes: ICD10Codes = Field(..., description=\"The ICD-10 codes of the patient\")\n",
        "    cpt_codes: CPTCodes = Field(..., description=\"The CPT codes of the patient. All codes relevant to the conversation should be suggested, it's ok to suggest codes you are not sure about\")\n",
        "\n",
        "\n",
        "def call_claude_with_tools(\n",
        "    prompt: str,\n",
        "    tools: List[Dict[str, Any]],\n",
        "    client: Any,\n",
        "    model: str = \"us.anthropic.claude-3-7-sonnet-20250219-v1:0\"\n",
        ") -> Any:\n",
        "    \"\"\"\n",
        "    Calls the Claude model with the provided prompt and tools.\n",
        "\n",
        "    Args:\n",
        "        prompt (str): The prompt to send to the model.\n",
        "        tools (List[Dict[str, Any]]): The list of tools (schemas) for extraction.\n",
        "        client (Any): The AnthropicBedrock client instance.\n",
        "        model (str): The model identifier.\n",
        "\n",
        "    Returns:\n",
        "        Any: The response from the Claude model.\n",
        "    \"\"\"\n",
        "    response = client.messages.create(\n",
        "        model=model,\n",
        "        messages=[{\"role\": \"user\", \"content\": prompt}],\n",
        "        tools=tools,\n",
        "        tool_choice={\"type\": \"tool\", \"name\": \"analyse_conversation_report\"},\n",
        "        max_tokens=5000,\n",
        "    )\n",
        "    return response\n",
        "\n",
        "\n",
        "def get_extraction_tools() -> List[Dict[str, Any]]:\n",
        "    \"\"\"\n",
        "    Returns the extraction tools (schemas) for the Claude model.\n",
        "\n",
        "    Returns:\n",
        "        List[Dict[str, Any]]: The list of tool schemas.\n",
        "    \"\"\"\n",
        "    tools = [\n",
        "        {\n",
        "            \"name\": \"analyse_conversation_report\",\n",
        "            \"description\": \"Analyze the conversation report.\",\n",
        "            \"input_schema\": ConversationReportAnalysis.schema(),\n",
        "        },\n",
        "    ]\n",
        "    return tools\n",
        "\n",
        "\n",
        "def load_conversation(conversation_file: str) -> str:\n",
        "    \"\"\"\n",
        "    Loads the conversation text from a file.\n",
        "\n",
        "    Args:\n",
        "        conversation_file (str): Path to the conversation file.\n",
        "\n",
        "    Returns:\n",
        "        str: The conversation text.\n",
        "    \"\"\"\n",
        "    with open(conversation_file, \"r\") as f:\n",
        "        return f.read()\n",
        "\n",
        "\n",
        "def create_report_from_conversation_report(conversation_report: Dict[str, Any]) -> str:\n",
        "    \"\"\"\n",
        "    Creates a formatted report string from the conversation report dictionary.\n",
        "\n",
        "    Args:\n",
        "        conversation_report (Dict[str, Any]): The conversation report with titles and values.\n",
        "\n",
        "    Returns:\n",
        "        str: The formatted report string.\n",
        "    \"\"\"\n",
        "    return f\"\"\"\n",
        "{conversation_report['chief_complaint']['title']}:\\n\\n{conversation_report['chief_complaint']['value']}\\n\\n\n",
        "{conversation_report['history_of_present_illness']['title']}:\\n\\n{conversation_report['history_of_present_illness']['value']}\\n\\n\n",
        "{conversation_report['past_medical_history']['title']}:\\n\\n{conversation_report['past_medical_history']['value']}\\n\\n\n",
        "{conversation_report['past_surgical_history']['title']}:\\n\\n{conversation_report['past_surgical_history']['value']}\\n\\n\n",
        "{conversation_report['medications']['title']}:\\n\\n{conversation_report['medications']['value']}\\n\\n\n",
        "{conversation_report['allergies']['title']}:\\n\\n{conversation_report['allergies']['value']}\\n\\n\n",
        "{conversation_report['family_history']['title']}:\\n\\n{conversation_report['family_history']['value']}\\n\\n\n",
        "{conversation_report['social_history']['title']}:\\n\\n{conversation_report['social_history']['value']}\\n\\n\n",
        "{conversation_report['review_of_systems']['title']}:\\n\\n{conversation_report['review_of_systems']['value']}\\n\\n\n",
        "{conversation_report['neurological']['title']}:\\n\\n{conversation_report['neurological']['value']}\\n\\n\n",
        "{conversation_report['psychiatric']['title']}:\\n\\n{conversation_report['psychiatric']['value']}\\n\\n\n",
        "{conversation_report['endocrine']['title']}:\\n\\n{conversation_report['endocrine']['value']}\\n\\n\n",
        "{conversation_report['hematologic_lymphatic']['title']}:\\n\\n{conversation_report['hematologic_lymphatic']['value']}\\n\\n\n",
        "{conversation_report['allergic_immunologic']['title']}:\\n\\n{conversation_report['allergic_immunologic']['value']}\\n\\n\n",
        "{conversation_report['physical_exam']['title']}:\\n\\n{conversation_report['physical_exam']['value']}\\n\\n\n",
        "{conversation_report['labs']['title']}:\\n\\n{conversation_report['labs']['value']}\\n\\n\n",
        "{conversation_report['imaging']['title']}:\\n\\n{conversation_report['imaging']['value']}\\n\\n\n",
        "{conversation_report['assessment_and_plan']['title']}:\\n\\n{conversation_report['assessment_and_plan']['value']}\\n\\n\n",
        "\"\"\"\n",
        "\n",
        "\n",
        "def extract_report_from_conversation(conversation_text: str) -> Dict[str, Any]:\n",
        "    \"\"\"\n",
        "    Extracts a structured report from the conversation text using the Claude model.\n",
        "\n",
        "    Args:\n",
        "        conversation_text (str): The conversation transcript.\n",
        "\n",
        "    Returns:\n",
        "        Dict[str, Any]: The structured report with titles and values.\n",
        "    \"\"\"\n",
        "    tools = get_extraction_tools()\n",
        "    client = AnthropicBedrock(aws_region=\"us-east-2\",)\n",
        "    prompt = f\"\"\"\n",
        "    You are a medical doctor, writting a medical report based on a conversation transcript.\n",
        "    Given the following conversation, extract the following feilds according to their structure guidelines if appears.\n",
        "\n",
        "    The fields are:\n",
        "    Chief Complaint (CC)\n",
        "    History of Present Illness (HPI) - Structure: Gender, Age, Relevant history titles, Chronological order of events, Substantive content\n",
        "    Past Medical History (PMH)\n",
        "    Past Surgical History (PSH)\n",
        "    Medications\n",
        "    Allergies\n",
        "    Family History\n",
        "    Social History\n",
        "    Review of Systems (ROS)\n",
        "    Neurological\n",
        "    Psychiatric\n",
        "    Endocrine\n",
        "    Hematologic/Lymphatic\n",
        "    Allergic/Immunologic\n",
        "    Physical Exam\n",
        "    Labs\n",
        "    Imaging\n",
        "    Assessment and Plan - Structure: One or two sentences summary, Assessment, Plan\n",
        "    ICD-10 Codes\n",
        "    CPT Codes (Suggest codes that you think are relevant to the conversation, it's ok to suggest codes you are not sure about)\n",
        "\n",
        "    For icd10_codes and cpt_codes, return results as dictionaries! Our lives depend on it!\n",
        "\n",
        "    The conversation transcript:\n",
        "    {conversation_text}\n",
        "    \"\"\"\n",
        "    time_start = time()\n",
        "    response = call_claude_with_tools(prompt, tools, client)\n",
        "    time_end = time()\n",
        "    print(f\"Claude call time: {time_end - time_start} seconds\")\n",
        "\n",
        "    model_output = response.content[0].input\n",
        "\n",
        "    if not isinstance(model_output.get(\"icd10_codes\"), dict):\n",
        "        model_output[\"icd10_codes\"] = {\"codes\": model_output[\"icd10_codes\"]}\n",
        "\n",
        "    if not isinstance(model_output.get(\"cpt_codes\"), dict):\n",
        "        model_output[\"cpt_codes\"] = {\"codes\": model_output[\"cpt_codes\"]}\n",
        "\n",
        "    report_parameters = ConversationReportAnalysis(**model_output)\n",
        "    report_parameters_with_titles = add_titles_to_report(report_parameters)\n",
        "    return report_parameters_with_titles\n",
        "\n",
        "\n",
        "def add_titles_to_report(report: ConversationReportAnalysis) -> Dict[str, Dict[str, Any]]:\n",
        "    \"\"\"\n",
        "    Adds titles and descriptions to each field in the report.\n",
        "\n",
        "    Args:\n",
        "        report (ConversationReportAnalysis): The report object.\n",
        "\n",
        "    Returns:\n",
        "        Dict[str, Dict[str, Any]]: The report with titles, descriptions, and values.\n",
        "    \"\"\"\n",
        "    schema = report.schema()\n",
        "    values = report.dict()\n",
        "    detailed_report = {\n",
        "        field: {\n",
        "            \"title\": schema[\"properties\"][field].get(\"title\", \"\"),\n",
        "            \"description\": schema[\"properties\"][field].get(\"description\", \"\"),\n",
        "            \"value\": values[field]\n",
        "        }\n",
        "        for field in values\n",
        "    }\n",
        "    return detailed_report\n",
        "\n",
        "\n",
        "def transcription_to_report_main(conversation_file: str, report_file: str):\n",
        "    \"\"\"\n",
        "    Main function to extract a report from a conversation file and save it.\n",
        "\n",
        "    Args:\n",
        "        conversation_file (str): Path to the conversation transcript file.\n",
        "        report_file (str): Path to save the generated report.\n",
        "    \"\"\"\n",
        "    conversation_text = load_conversation(conversation_file)\n",
        "    report_parameters = extract_report_from_conversation(conversation_text)\n",
        "    with open(report_file.replace(\".txt\", \".json\"), \"w\") as f:\n",
        "        json.dump(report_parameters, f, indent=4)\n",
        "    report_text = create_report_from_conversation_report(report_parameters)\n",
        "    with open(report_file, \"w\") as f:\n",
        "        f.write(report_text)\n"
      ],
      "id": "11c6f34dce29316f"
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 2
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython2",
      "version": "2.7.6"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}